# --------------------------------------------------------------
# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License.
# --------------------------------------------------------------
# Dockerfile to run ONNXRuntime with TensorRT integration

# nVidia TensorRT Base Image
ARG TRT_CONTAINER_VERSION=22.07
FROM nvcr.io/nvidia/tensorrt:${TRT_CONTAINER_VERSION}-py3

RUN python -m pip install --upgrade pip
RUN pip install onnxruntime-gpu==1.12.1
RUN pip install onnxmltools
RUN pip install pandas

#RUN pip install mlperf_loadgen --extra-index-url https://olivewheels.azureedge.net/test

#RUN /opt/miniconda/bin/conda update libstdcxx-ng

COPY . /onnx-olive
WORKDIR /onnx-olive
RUN pip install -e .

# Example invocation:
# docker run -it --rm --gpus all -v /home/ubuntu/models:/models -v `pwd`/configs:/configs  octoml/olive:trt  /models/yolov5s_dynamic.onnx  /configs/yolov5s_dynamic.json /configs/config-trt-short.json
ENTRYPOINT [ "python", "./olive/preprocess.py"]
